{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, ImageDataGenerator, img_to_array, array_to_img\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Cardboard',\n",
       " 1: 'Chips Bag',\n",
       " 2: 'Drinking Carton',\n",
       " 3: 'Glass Bottle',\n",
       " 4: 'Glass Cup',\n",
       " 5: 'Metal Can',\n",
       " 6: 'Organic',\n",
       " 7: 'Paper',\n",
       " 8: 'Plastic Bag',\n",
       " 9: 'Plastic Bottle',\n",
       " 10: 'Plastic Box',\n",
       " 11: 'Plastic Round Container'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = {0:'Cardboard', 1:'Chips Bag', 2:'Drinking Carton', 3:'Glass Bottle',\n",
    "                   4:'Glass Cup', 5:'Metal Can', 6:'Organic', 7:'Paper', 8:'Plastic Bag',\n",
    "                   9:'Plastic Bottle', 10:'Plastic Box', 11:'Plastic Round Container'}\n",
    "\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "NASNetLarge_model = load_model(\"nasnetlarge_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Plastic Bottle'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = \"test_image.jpeg\"\n",
    "test_image_path = (img_to_array(load_img(image_path, target_size = (331,331)))/255.).reshape(1,331,331,3)\n",
    "results = np.argmax((NASNetLarge_model(test_image_path)).numpy(), axis = -1)\n",
    "labels[int(results)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "\n",
    "    # rectangle for user to play\n",
    "    cv2.rectangle(frame, (100, 100), (500, 500), (255, 255, 255), 2)\n",
    "\n",
    "    # extract the region of image within the user rectangle\n",
    "    roi = frame[100:500, 100:500]\n",
    "    img = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (331, 331))\n",
    "    img = img_to_array(img)\n",
    "    img = img/ 255\n",
    "    \n",
    "    # predict the move made\n",
    "    pred = NASNetLarge_model.predict(np.array([img]))\n",
    "    max_index = np.argmax(pred[0])\n",
    "    predicted_label = labels[max_index]\n",
    "    \n",
    "\n",
    "\n",
    "    # display the information\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(frame, predicted_label, (50, 50), font, 1.2, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "#     cv2.putText(img, predicted_label, (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "\n",
    "    cv2.imshow(\"Recycle Prediction\", frame)\n",
    "\n",
    "    k = cv2.waitKey(10)\n",
    "    if k == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Testing with DenseNet169 </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "densenet_model = load_model(\"densenet169_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "\n",
    "    # rectangle for user to play\n",
    "    cv2.rectangle(frame, (100, 100), (500, 500), (255, 255, 255), 2)\n",
    "\n",
    "    # extract the region of image within the user rectangle\n",
    "    roi = frame[100:500, 100:500]\n",
    "    img = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = img_to_array(img)\n",
    "    img = img/ 255\n",
    "    \n",
    "    # predict the move made\n",
    "    pred = densenet_model.predict(np.array([img]))\n",
    "    max_index = np.argmax(pred[0])\n",
    "    predicted_label = labels[max_index]\n",
    "    \n",
    "\n",
    "\n",
    "    # display the information\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(frame, predicted_label, (50, 50), font, 1.2, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "#     cv2.putText(img, predicted_label, (int(x), int(y)), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)\n",
    "\n",
    "    cv2.imshow(\"Recycle Prediction\", frame)\n",
    "\n",
    "    k = cv2.waitKey(10)\n",
    "    if k == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
